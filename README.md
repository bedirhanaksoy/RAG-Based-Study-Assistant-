# üìò RAG-Based Study Assistant

**RAG-Based Intelligent Study Assistant for Document-Oriented Question Answering and Flashcard Generation**

This project is a **fully local, end-to-end Retrieval-Augmented Generation (RAG)** application designed to help users study large PDF documents efficiently through a built-in web interface.

The system allows users to upload textbooks or lecture notes, ask document-grounded questions, and generate flashcards,  all while running entirely on a local machine.

---

## üöÄ Key Features

- üìö Upload and manage multiple PDF documents
- ‚ùì Ask questions grounded in the selected document
- üß† Generate flashcards using the same RAG pipeline
- üìÑ Page-level source attribution for answers
- ‚ö° Persistent FAISS vector indexes (no recomputation)
- üîí No external APIs, no cloud dependency

---
## üß† RAG Pipeline

```

PDF  
‚Üí Text Cleaning & Chunking  
‚Üí Embedding Model  
‚Üí FAISS Vector Index  
‚Üí Retriever  
‚Üí Local LLM (Gemma)  
‚Üí Answer / Flashcards + Sources  

````

The same retrieval pipeline is reused for:
- Question answering
- Flashcard generation

---

## üõ†Ô∏è Installation

### 1Ô∏è‚É£ Create virtual environment and install requirements

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
````

### 2Ô∏è‚É£ Download local LLM model

To download the **Gemma 3-1b IT** model locally, run:

```bash
python3 setup.py
```

> ‚ö†Ô∏è This step requires logging in to Hugging Face to download the model weights.  
> Follow the error messages if authentication is required.

---

## ‚ñ∂Ô∏è Run the Server

```bash
uvicorn server.rag_server:app --reload --port 8000
```

Then open:

```
http://localhost:3000
```

You can now:

- Upload a PDF from the UI
    
- Select a document
    
- Ask questions
    
- Generate flashcards
    

---

## üß† Core Technologies

- **LLM:** Google Gemma (instruction-tuned, ~1B parameters)
    
- **Embeddings:** Sentence-level dense embeddings
    
- **Vector Store:** FAISS (local, persistent)
    
- **Backend:** FastAPI
    
- **Frontend:** Next.js
    
- **Storage:**
    
    - `.index` files for FAISS embeddings
        
    - `_meta.csv` files for text chunks & page numbers
        

---

## ‚ö†Ô∏è Limitations

    
- First-time embedding generation may be slow for large PDFs
    
- Retrieval quality is not yet quantitatively evaluated
    

---

## üìö Acknowledgements

This project‚Äôs RAG pipeline design was mainly influenced by the following tutorial:

- **Daniel Bourke ‚Äì Local Retrieval Augmented Generation (RAG) from Scratch**  
    [https://www.youtube.com/watch?v=qN_2fnOPY-M](https://www.youtube.com/watch?v=qN_2fnOPY-M)
    

---

## üë• Authors

- **Bedirhan √ñmer Aksoy**
- **Ahmet Semih Marufoƒülu**
